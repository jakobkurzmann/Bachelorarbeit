{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Node Embeddings with Properties\n",
    "\n",
    "In this step, we extract temporal features from the timestamps stored in the `validFrom` and `validTo` properties of each `Trip` node. These include basic components like year, month, day, hour, and minute, as well as derived attributes such as weekday, weekend and season. The resulting values are stored as new node properties and will later be used as input features for the FastRP algorithm.\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "ef7df2f72cfcd28d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Import the required libraries\n",
    "First of all we have to install and import the libraries that we need for the implementation of the Temporal Node Embedding.\n",
    "\n",
    "- neo4j: The Neo4j Python driver is used to connect to the Neo4j database.\n",
    "- graphdatascience: The graph datascience client is a Python client for working with the Neo4j Graph Data Science Library which is used for the in-memory graph projection and the FastRP algorithm for the embedding.\n"
   ],
   "id": "f644373649af2d17"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%pip install neo4j\n",
    "%pip install graphdatascience\n",
    "%pip install holidays"
   ],
   "id": "5639a69b4f220655",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from neo4j import GraphDatabase\n",
    "import graphdatascience\n",
    "import holidays\n",
    "from datetime import datetime"
   ],
   "id": "625291b2c47b9b37",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Configure Driver and Client\n",
    "\n",
    "We have to configure the driver and the client for the connection to the Neo4j database. The driver is used to execute Cypher queries and the client is used to execute the Graph Data Science Library algorithms. \n",
    "\n",
    "- Endpoint: Bolt URL of the Neo4j database \n",
    "- Username: Username \n",
    "- Password: Password\n",
    "- database: Database where you imported the trips"
   ],
   "id": "d5cebe4df848e25f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T12:01:29.976742Z",
     "start_time": "2025-04-19T12:01:29.886196Z"
    }
   },
   "cell_type": "code",
   "source": [
    "endpoint = \"neo4j://localhost:7687\"\n",
    "username = \"neo4j\"\n",
    "password = \"#Bachelorarbeit\"\n",
    "database = \"neo4j\"\n",
    "\n",
    "gds = graphdatascience.GraphDataScience(endpoint=endpoint, auth=(username, password))\n",
    "gds.set_database(database)\n",
    "\n",
    "db_driver = GraphDatabase.driver(endpoint, auth=(username,password))"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Adding Derived Temporal Node Properties from Timestamps\n",
    "In this step, temporal features are extracted from the `validFrom` and `validTo` properties of each `Trip` node. These include basic components like year, month, day, hour, and minute, as well as derived attributes such as weekday, weekend indicator, and season. The values are stored as new node properties and will later be used as input features for the FastRP algorithm.\n",
    "\n",
    "To support future interval-based analyses and to avoid reprocessing timestamps, both start and end features (e.g., `startDay`, `endDay`, etc.) are stored, even if in this case only a single timestamp is relevant. If the embedding is based on a single point in time, only the corresponding features would be needed.\n"
   ],
   "id": "8fca9228fb064fdd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "query = \"\"\"\n",
    "MATCH (t:Trip)\n",
    "SET t.startYear = t.validFrom.year,\n",
    "    t.startMonth = t.validFrom.month,\n",
    "    t.startDay = t.validFrom.day,\n",
    "    t.startHour = t.validFrom.hour,\n",
    "    t.startMinute = t.validFrom.minute,\n",
    "    t.startSeason = CASE\n",
    "        WHEN t.validFrom.month IN [12, 1, 2] THEN 1\n",
    "        WHEN t.validFrom.month IN [3, 4, 5] THEN 2\n",
    "        WHEN t.validFrom.month IN [6, 7, 8] THEN 3\n",
    "        WHEN t.validFrom.month IN [9, 10, 11] THEN 4\n",
    "        ELSE 0\n",
    "    END,\n",
    "    t.startIsWeekend = CASE\n",
    "        WHEN t.validFrom.dayOfWeek IN [6, 7] THEN 1\n",
    "        WHEN t.validFrom.dayOfWeek IN [1, 2, 3, 4, 5] THEN 0\n",
    "        ELSE 0\n",
    "    END,\n",
    "    t.startWeekday = t.validFrom.dayOfWeek,\n",
    "    t.endYear = t.validTo.year,\n",
    "    t.endMonth = t.validTo.month,\n",
    "    t.endDay = t.validTo.day,\n",
    "    t.endHour = t.validTo.hour,\n",
    "    t.endMinute = t.validTo.minute,\n",
    "    t.endSeason = CASE\n",
    "        WHEN t.validTo.month IN [12, 1, 2] THEN 1\n",
    "        WHEN t.validTo.month IN [3, 4, 5] THEN 2\n",
    "        WHEN t.validTo.month IN [6, 7, 8] THEN 3\n",
    "        WHEN t.validTo.month IN [9, 10, 11] THEN 4\n",
    "        ELSE 0\n",
    "    END,\n",
    "    t.endIsWeekend = CASE\n",
    "        WHEN t.validTo.dayOfWeek IN [6, 7] THEN 1\n",
    "        WHEN t.validTo.dayOfWeek IN [1, 2, 3, 4, 5] THEN 0\n",
    "        ELSE 0\n",
    "    END,\n",
    "    t.endWeekday = t.validTo.dayOfWeek\n",
    "\n",
    "\"\"\"\n",
    "with db_driver.session(database=database) as session:\n",
    "        session.run(query)"
   ],
   "id": "93be526e79376c2a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "###  Annotating Trips with Holiday Information\n",
    "\n",
    "In the context of bike sharing in New York City, certain contextual factors—such as public holidays—can significantly influence user behavior. To capture this, each `Trip` node is annotated with an `isHoliday` property based on the `validFrom` timestamp and the official US holidays for New York State.\n",
    "\n",
    "This additional temporal feature allows for more nuanced analyses and can help improve downstream tasks like demand prediction. The annotation is done in batches for performance reasons using the APOC library.\n"
   ],
   "id": "ffe17b133badfa3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 23min\n",
    "ny_holidays = holidays.country_holidays('US', subdiv='NY')\n",
    "\n",
    "def check_holidays(date_obj):\n",
    "    if isinstance(date_obj, datetime):\n",
    "        return int(date_obj.date() in ny_holidays)\n",
    "    return 0\n",
    "\n",
    "def annotate_holidays_batchwise(driver, batch_size=500):\n",
    "    with driver.session(database=database) as session:\n",
    "        result = session.run(\"\"\"\n",
    "            MATCH (t:Trip)\n",
    "            WHERE t.validFrom IS NOT NULL\n",
    "            RETURN id(t) AS node_id, t.validFrom AS startTime\n",
    "        \"\"\")\n",
    "\n",
    "        batch = []\n",
    "        batches_sent = 0\n",
    "\n",
    "        for record in result:\n",
    "            try:\n",
    "                start_time = record[\"startTime\"]\n",
    "                is_holiday = check_holidays(start_time.to_native())\n",
    "                batch.append({\n",
    "                    \"node_id\": record[\"node_id\"],\n",
    "                    \"isHoliday\": is_holiday\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping node {record['node_id']}: {e}\")\n",
    "\n",
    "            if len(batch) >= batch_size:\n",
    "                _send_isHoliday_batch(driver, batch)\n",
    "                batches_sent += batch_size\n",
    "                print(f\"{batches_sent} holiday annotations written\")\n",
    "                batch = []\n",
    "\n",
    "        if batch:\n",
    "            _send_isHoliday_batch(driver, batch)\n",
    "\n",
    "def _send_isHoliday_batch(driver, batch):\n",
    "    query = \"\"\"\n",
    "    CALL apoc.periodic.iterate(\n",
    "      'UNWIND $batch AS row RETURN row',\n",
    "      '\n",
    "      MATCH (t:Trip) WHERE id(t) = row.node_id\n",
    "      SET t.isHoliday = row.isHoliday\n",
    "      ',\n",
    "      {batchSize: 100, parallel: true, params: {batch: $batch}}\n",
    "    )\n",
    "    \"\"\"\n",
    "    with driver.session(database=database) as session:\n",
    "        session.run(query, batch=batch)\n",
    "\n",
    "annotate_holidays_batchwise(db_driver)\n"
   ],
   "id": "8bdbb20c54c4caff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Assigning Temporal Properties to Station Nodes\n",
    "In order to generate node embeddings using feature-based algorithms like FastRP, all nodes in the embedded graph must share the same set of properties. This ensures that the embedding algorithm can compute meaningful and comparable vectors across different node types.\n",
    "\n",
    "In this bike-sharing graph, Trip nodes inherently contain temporal information such as start and end timestamps. However, Station nodes do not carry any temporal attributes by default. To embed both node types into the same feature space, we need to assign analogous temporal properties to Station nodes.\n",
    "\n",
    "The following Python code achieves this by generating random but reproducible temporal features for each Station node. The node's unique ID (station_id) is used as a seed to ensure that the same properties are assigned every time the script is run."
   ],
   "id": "c5a36a4914c51752"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T12:02:35.142861Z",
     "start_time": "2025-04-19T12:02:34.769709Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "\n",
    "def generate_properties_for_station(station_id):\n",
    "    rnd = random.Random(f\"{station_id}_start\")  # use a consistent seed per station\n",
    "\n",
    "    return {\n",
    "        \"startYear\": 2017,\n",
    "        \"startMonth\": rnd.randint(1, 12),\n",
    "        \"startDay\": rnd.randint(1, 28),  # safe to keep Feb valid\n",
    "        \"startHour\": rnd.randint(0, 23),\n",
    "        \"startMinute\": rnd.randint(0, 59),\n",
    "        \"startWeekday\": rnd.randint(0, 6),\n",
    "        \"startIsHoliday\": rnd.randint(0, 1),\n",
    "        \"startSeason\": rnd.randint(0, 3),\n",
    "        \"startIsWeekend\": rnd.randint(0, 1),\n",
    "    }\n",
    "\n",
    "def generate_end_properties_for_station(station_id):\n",
    "    rnd = random.Random(f\"{station_id}_end\")\n",
    "\n",
    "    return {\n",
    "        \"endYear\": 2017,\n",
    "        \"endMonth\": rnd.randint(1, 12),\n",
    "        \"endDay\": rnd.randint(1, 28),\n",
    "        \"endHour\": rnd.randint(0, 23),\n",
    "        \"endMinute\": rnd.randint(0, 59),\n",
    "        \"endWeekday\": rnd.randint(0, 6),\n",
    "        \"endIsHoliday\": rnd.randint(0, 1),\n",
    "        \"endSeason\": rnd.randint(0, 3),\n",
    "        \"endIsWeekend\": rnd.randint(0, 1),\n",
    "    }\n",
    "\n",
    "def write_station_properties_batchwise(driver, batch_size=500):\n",
    "    with driver.session(database=database) as session:\n",
    "        result = session.run(\"MATCH (s:Station) RETURN id(s) AS station_id\")\n",
    "\n",
    "        batch = []\n",
    "        count = 0\n",
    "        for record in result:\n",
    "            sid = record[\"station_id\"]\n",
    "\n",
    "            try:\n",
    "                props = generate_properties_for_station(sid)\n",
    "                props.update(generate_end_properties_for_station(sid))\n",
    "                props[\"station_id\"] = sid\n",
    "\n",
    "                batch.append(props)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping station {sid}: {e}\")\n",
    "\n",
    "            if len(batch) >= batch_size:\n",
    "                _send_station_property_batch(driver, batch)\n",
    "                count += len(batch)\n",
    "                print(f\"{count} stations processed.\")\n",
    "                batch = []\n",
    "\n",
    "        if batch:\n",
    "            _send_station_property_batch(driver, batch)\n",
    "\n",
    "def _send_station_property_batch(driver, batch):\n",
    "    query = \"\"\"\n",
    "    CALL apoc.periodic.iterate(\n",
    "      'UNWIND $batch AS row RETURN row',\n",
    "      '\n",
    "      MATCH (s:Station) WHERE id(s) = row.station_id\n",
    "      SET s.startYear = row.startYear,\n",
    "          s.startMonth = row.startMonth,\n",
    "          s.startDay = row.startDay,\n",
    "          s.startHour = row.startHour,\n",
    "          s.startMinute = row.startMinute,\n",
    "          s.startWeekday = row.startWeekday,\n",
    "          s.startIsHoliday = row.startIsHoliday,\n",
    "          s.startSeason = row.startSeason,\n",
    "          s.startIsWeekend = row.startIsWeekend,\n",
    "          s.endYear = row.endYear,\n",
    "          s.endMonth = row.endMonth,\n",
    "          s.endDay = row.endDay,\n",
    "          s.endHour = row.endHour,\n",
    "          s.endMinute = row.endMinute,\n",
    "          s.endWeekday = row.endWeekday,\n",
    "          s.endIsHoliday = row.endIsHoliday,\n",
    "          s.endSeason = row.endSeason,\n",
    "          s.endIsWeekend = row.endIsWeekend\n",
    "      ',\n",
    "      {batchSize: 100, parallel: true, params: {batch: $batch}}\n",
    "    )\n",
    "    \"\"\"\n",
    "    with driver.session(database=database) as session:\n",
    "        session.run(query, batch=batch)\n",
    "\n",
    "write_station_properties_batchwise(db_driver)\n"
   ],
   "id": "8a9df8d5ae2217d2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 stations processed.\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Temporal Node Embedding with FastRP\n",
    "\n",
    "In this section we will create the in-memory graph projection of the Graph and apply the FastRP algorithm to embed the nodes.\n"
   ],
   "id": "e66c5839e7c60994"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Create the In-Memory Graph Projection\n",
    "First we create the in-memory graph projection. This is necessary to apply the FastRP algorithm. Projected graphs can also include additional numerical properties from the original graph."
   ],
   "id": "d2fab1ac25d0f1fe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Query braucht 2min\n",
    "\n",
    "projection_query  = \"\"\"\n",
    "MATCH (source)-[r:HAS_START|HAS_END]->(target)\n",
    "WHERE source:Trip AND target:Station\n",
    "WITH gds.graph.project(\n",
    "  'propertiesGraph',\n",
    "  source,\n",
    "  target,\n",
    "  {\n",
    "    sourceNodeProperties: source {\n",
    "      year: source.startYear,\n",
    "      month: source.startMonth,\n",
    "      day: source.startDay,\n",
    "      hour: source.startHour,\n",
    "      minute: source.startMinute,\n",
    "      weekday: source.startWeekday,\n",
    "      season: source.startSeason,\n",
    "      isWeekend: source.startIsWeekend,\n",
    "      isHoliday: source.startIsHoliday\n",
    "    },\n",
    "    targetNodeProperties: target {\n",
    "      year: target.startYear,\n",
    "      month: target.startMonth,\n",
    "      day: target.startDay,\n",
    "      hour: target.startHour,\n",
    "      minute: target.startMinute,\n",
    "      weekday: target.startWeekday,\n",
    "      season: target.startSeason,\n",
    "      isWeekend: target.startIsWeekend,\n",
    "      isHoliday: target.startIsHoliday\n",
    "    }},\n",
    "  {undirectedRelationshipTypes: ['*']}\n",
    ") AS g\n",
    "RETURN g.graphName AS graph, g.nodeCount AS nodes, g.relationshipCount AS rels\n",
    "\"\"\"\n",
    "with db_driver.session(database=database) as session:\n",
    "    session.run(projection_query)"
   ],
   "id": "3becfd869b5f1da7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now we will check if we created the memory graph correctly and save it into the variable G.",
   "id": "5d5fd35eecab3ab9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "G = gds.graph.get(\"propertiesGraph\")",
   "id": "7a9086c75391ed89",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### FastRP Algorithm Estimation\n",
    "We estimate the FastRP algorithm. If we checked those with our resources we can run the FastRP algorithm to embed the nodes of the Time Tree."
   ],
   "id": "86197326c71d9020"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "gds.fastRP.write.estimate(\n",
    "    G,\n",
    "    writeProperty=\"propertyEmbedding\",\n",
    "    randomSeed = 42,\n",
    "    embeddingDimension= 128,\n",
    "    nodeSelfInfluence = 1.0,\n",
    "    propertyRatio = 0.5,\n",
    "    featureProperties = ['month','day', 'hour', 'minute', 'weekday', 'season', 'isWeekend', 'isHoliday'],\n",
    "    iterationWeights = [1.0]\n",
    ")"
   ],
   "id": "84b51cdf4eb226c0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### FastRP Algorithm Execution\n",
    "Now we run the FastRP algorithm to embed the nodes of the Time Tree. We will write the embedding into the propertyEmbedding."
   ],
   "id": "b6d7144c045e659"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#40min\n",
    "gds.fastRP.write(\n",
    "    G,\n",
    "    writeProperty=\"propertyEmbedding\",\n",
    "    randomSeed = 42,\n",
    "    embeddingDimension=128,\n",
    "    nodeSelfInfluence=0.4,\n",
    "    propertyRatio = 0.5,\n",
    "    featureProperties = ['month','day', 'hour', 'minute', 'weekday', 'season', 'isWeekend', 'isHoliday'],\n",
    "    iterationWeights = [1.0]\n",
    ")"
   ],
   "id": "36ded48c0ef490dd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Dropping Graph and Closing Connection\n",
    "After we have finished the embedding we can drop the graph and close the connection to the database."
   ],
   "id": "4b3beb84fed7732a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "G.drop()",
   "id": "2d4892bdf51e1522",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_vector_index(index_name, label, property_name, vector_dimension, similarity=\"cosine\"):\n",
    "    query = f\"\"\"\n",
    "    CREATE VECTOR INDEX {index_name}\n",
    "    FOR (n:{label})\n",
    "    ON (n.{property_name})\n",
    "    OPTIONS {{\n",
    "    indexConfig: {{\n",
    "        `vector.dimensions`: {vector_dimension},\n",
    "        `vector.similarity_function`: '{similarity}'\n",
    "        }}\n",
    "    }}\n",
    "    \"\"\"\n",
    "    with db_driver.session(database=database) as session:\n",
    "        session.run(query)\n",
    "\n",
    "create_vector_index( 'propertyIndex','Trip', 'propertyEmbedding', '128')"
   ],
   "id": "c87edefe526b0ce8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "gds.close()\n",
    "db_driver.close()"
   ],
   "id": "edc48a16936f5511",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
